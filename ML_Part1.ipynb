{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbors Classifier on Imbalanced Dataset\n",
        "\n",
        "## 1. Import Necessary Libraries\n"
      ],
      "metadata": {
        "id": "4BcllkC3-Ugr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for data manipulation and machine learning\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "tJfdNuuP-WDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load and Balance the Dataset\n"
      ],
      "metadata": {
        "id": "riTSuH4S-fgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uJVZtx0L-1I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('magic04.data', header=None)\n",
        "\n",
        "# Separate gamma ('g') and hadron ('h') classes\n",
        "gamma = data[data.iloc[:, -1] == 'g']\n",
        "hadron = data[data.iloc[:, -1] == 'h']\n",
        "\n",
        "# Balance the dataset by downsampling the gamma class\n",
        "gamma_less = gamma.sample(n=len(hadron), random_state=42)"
      ],
      "metadata": {
        "id": "NCgN4enB-8xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Split the Dataset into Training, Validation, and Test Sets\n"
      ],
      "metadata": {
        "id": "ZUZv90qE-_Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split data\n",
        "# train test and validation from gamma\n",
        "temp, g_test = train_test_split(gamma_less, test_size= 0.15, random_state= 42)\n",
        "g_train, g_val = train_test_split(temp, test_size= 0.1765, random_state= 42)\n",
        "\n",
        "# train test and validation from hadron\n",
        "temp, h_test = train_test_split(hadron, test_size= 0.15, random_state= 42)\n",
        "h_train, h_val = train_test_split(temp, test_size= 0.1765, random_state= 42)\n",
        "\n",
        "train = pd.concat([g_train, h_train])\n",
        "val = pd.concat([g_val, h_val])\n",
        "test = pd.concat([g_test, h_test])\n",
        "\n",
        "# Separate features and target labels\n",
        "x_train = train.iloc[:, :-1]\n",
        "y_train = train.iloc[:, -1]\n",
        "\n",
        "x_val = val.iloc[:, :-1]\n",
        "y_val = val.iloc[:, -1]\n",
        "\n",
        "x_test = test.iloc[:, :-1]\n",
        "y_test = test.iloc[:, -1]"
      ],
      "metadata": {
        "id": "ePi4z4Ok_CtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Apply the K-Nearest Neighbors Classifier with Different K Values\n"
      ],
      "metadata": {
        "id": "cacvOAZn_Wob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different values of K\n",
        "k_values = range(1, 151, 5)\n",
        "results = []\n",
        "\n",
        "# Loop to evaluate each K\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "    knn.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = knn.predict(x_val)\n",
        "\n",
        "    # Calculate metrics for each K value\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    prec = precision_score(y_val, y_pred, pos_label='g')\n",
        "    recall = recall_score(y_val, y_pred, pos_label='g')\n",
        "    f1 = f1_score(y_val, y_pred, pos_label='g')\n",
        "    conf_m = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    results.append({'K': k, 'Accuracy': acc, 'Precision': prec, 'Recall': recall, 'F1-Score': f1, 'Confusion Matrix': conf_m})\n"
      ],
      "metadata": {
        "id": "Tem6MSHx_cze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Select the Best K Value Based on F1-Score\n"
      ],
      "metadata": {
        "id": "szjTv7zP_kFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best K based on validation set F1-Score\n",
        "best_result = max(results, key=lambda x: x['F1-Score'])\n",
        "best_k = best_result['K']\n",
        "print(f\"Best K based on validation set: {best_k}\")\n"
      ],
      "metadata": {
        "id": "zRTHPCvH_ndt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Train the Model with the Best K Value and Evaluate on the Test Set\n"
      ],
      "metadata": {
        "id": "BSCOxjh-_p9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the final model\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k, metric='euclidean')\n",
        "knn.fit(x_train, y_train)\n",
        "y_pred = knn.predict(x_test)\n",
        "\n",
        "# Calculate final evaluation metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, pos_label='g')\n",
        "recall = recall_score(y_test, y_pred, pos_label='g')\n",
        "f1 = f1_score(y_test, y_pred, pos_label='g')\n",
        "conf_m = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print final test set results\n",
        "print(\"\\nFinal Test Set Evaluation\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_m}\")\n"
      ],
      "metadata": {
        "id": "H3QAHqFg_uci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Analysis of Different K Values and Model Performance\n",
        "\n",
        "As K increases:\n",
        "- **Higher K values** smooth out decision boundaries by considering a larger neighborhood for classification. This can increase model stability and reduce sensitivity to noise.\n",
        "- **Lower K values** consider fewer neighbors, which can make the model sensitive to individual points and overfit to the training data.\n",
        "\n",
        "In this task, we used the F1-score to select the best K value since it balances precision and recall, particularly useful in cases with imbalanced classes. The best K was found to be **6** based on validation F1-score.\n",
        "\n",
        "Below, we examine the model's performance with K=6 on the test set."
      ],
      "metadata": {
        "id": "zPEKj0N0_zYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Final Test Set Evaluation\n",
        "\n",
        "### Final Evaluation Metrics\n",
        "' Accuracy: 0.7550\n",
        "\n",
        "' Precision: 0.7003\n",
        "\n",
        "' Recall: 0.8914\n",
        "\n",
        "' F1-Score: 0.7844\n",
        "\n",
        "' Confusion Matrix:\n",
        "\n",
        "' [[895 109]\n",
        "'  [383 621]]\n",
        "\n",
        "### Interpretation of Results\n",
        "- **Accuracy (75.50%)**: This metric suggests that the model correctly classifies around 76% of test samples.\n",
        "- **Precision (70.03%)**: Precision indicates that when the model predicts 'gamma' (signal), it is correct 70.03% of the time. This lower precision might be due to the influence of noisy or overlapping features.\n",
        "- **Recall (89.14%)**: A high recall indicates that the model successfully captures most of the 'gamma' signals. The model effectively avoids false negatives, which could be crucial if identifying all 'gamma' samples is essential.\n",
        "- **F1-Score (78.44%)**: The F1-score provides a balance between precision and recall, making it a valuable indicator of the model's overall reliability in handling both classes.\n",
        "\n",
        "### Confusion Matrix Interpretation\n",
        "- **True Positives (895)**: Correctly identified gamma ('g') samples.\n",
        "- **True Negatives (621)**: Correctly identified hadron ('h') samples.\n",
        "- **False Positives (109)**: Samples predicted as 'gamma' that are actually 'hadron'.\n",
        "- **False Negatives (383)**: Samples predicted as 'hadron' that are actually 'gamma'.\n",
        "\n",
        "### Observations on K's Influence\n",
        "\n",
        "As K values were adjusted, smaller values resulted in higher precision but lower recall, suggesting overfitting, while larger values improved recall at the cost of precision. This indicates a trade-off, with higher K values leading to a more generalized and stable model. Ultimately, K=6 struck a good balance for this dataset, optimizing recall and minimizing misclassification, aligning well with the goal of robust classification between 'gamma' and 'hadron' classes."
      ],
      "metadata": {
        "id": "xJ_r65T6Aw9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BON0J_NB-dT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D9pxWh-CB9e2"
      }
    }
  ]
}